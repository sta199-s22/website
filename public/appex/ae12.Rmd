---
title: 'Foundations of Inference'
output:
  html_document:
    df_print: paged
date: "02.16.2022"
editor_options:
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE)
```

# Bulletin
- Announcements
  - Reminder: [Teamwork grade](https://sta199-sp22-003.netlify.app/syllabus/syllabus.pdf)
  - [Updated FAQ](https://sta199-sp22-003.netlify.app/faq/faq.html)

# Today

By the end of today you will

- learn to simulate from a binomial distribution
- be able to define **Bernoulli distribution**, **Binomial distribution**,  **data-generative model** and **random variable**

```{r load-packages}
library(tidyverse)
```

## Scenario

*Your friend wants to play a game. The game goes: your friend flips a coin. If it's tails, you give your friend a dollar and if it's heads, your friend gives you a dollar.*

Let's flip a real coin and see how this game would go.

We will say a Tails is 0 and a Heads is 1. To be more precise, we will say: 

Let $X$ be a **random variable** that maps the outcome ("Heads, "Tails") to the numbers (1, 0) respectively.

A **random variable** takes each outcome (possibly a categorical variable) in the sample space and maps it to a number.

### Exercise 1

Input the data.

```{r flip-coin}
#coin_flips = c()
```

Do you think this coin is fair? Why?


### Exercise 2

Let's come up with a **data generative process**, a model for how the data was generated.

We might imagine that $X$ (the outcome of an individual coin flip, represented as 0 or 1) is obeying some universal law. Each time I flip the coin, there is a probability $p$ that the coin lands heads. What is the probability the coin lands tails? 

This probability $p$ is fixed to this coin. For example, some scenarios:

- the coin is fair, $p = 0.5$
- the coin is double-sided, $p = 0$ or $p = 1$
- the coin is weighted slightly in favor tails: $p = 0.4$

We say "X is Bernoulli distributed with parameter $p$."

$$
X \sim \text{Bernoulli}(p)
$$

this means $pr(X = 1) = p$ and $pr(X = 0) = 1-p$.

Now we can frame questions about the coin being fair in terms of $p$.

## Scenario 2

You decide you want to collect more data, but playing with your friend is getting expensive. You apply to (and are awarded) an NSF grant so that you no longer have to risk your own money to collect data. With new found confidence you approach your friend to play again.

```{r coin-flips-part-2}
#coin_flips = c(coin_flips, )
```

### Exercise 3

What's the probability of this outcome if the coin is fair?


More generally, we can define $Y$ to be the number of heads. In other words$Y = \sum_{i=1}^{12} X_i = X_1 + X_2 + ... X_{12}$

We say "Y is binomially distributed with parameters $n$ and $p$. $n$ is the total number of coin flips.
$$
Y \sim \text{Binomial}(n, p)
$$

this means:

$$
Pr(Y = y) = {n \choose y} p^{y} (1-p)^{n-y}
$$
Notice:

- the number of heads observed is lower case $y$
- $y$ is the number of heads
- $n-y$ is the number of tails


## Simulation

We can validate our analytical results above via simulation.

```{r binomial-simulation}
total_heads = rbinom(100000, 12, 0.5)
```

## Exercise 4

- Using `?rbinom` what does the function above do?

## Exercise 5

Using the code below to start, find the probability of seeing 11 tails from your simulation.
```{r prob-11-}
# flips = data.frame(total_heads)
```

Plot a histogram of your simulation. What does this show?

```{r histogram-coins}
# code here
```


## Exercise 6

What's the probability of seeing *at least* 11 tails?

```{r at-least-11}
# code here
```

