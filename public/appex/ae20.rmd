---
title: "Regression 2: Multiple regression"
date: "March 23 2022"
output:
  html_document:
    df_print: paged
---

```{r, warning = FALSE, message  = FALSE}
library(tidyverse)
library(tidymodels)
library(scatterplot3d)
library(viridis)
```

# Bulletin

- Due today
  - prep quiz 06

- Upcoming
  - Draft report due Monday March 28 to GitHub. Have your .Rmd **and** a PDF in GitHub


# Today

By the end of today, you will...

- understand least squares objective
- explain and compare $R^2$ statistics
- conduct a hypothesis test about a particular $\beta_i$
- model interactions between variables

We'll continue examining the Palmer penguin dataset.

```{r load-iris}
data(penguins)
```

Use `?penguins` or [click here](https://github.com/allisonhorst/palmerpenguins) for more info about the dataset.

# Last time 

## One predictor model

Recall that $y$ is the actual observed outcome (from the data) and $\hat{y}$ is the predicted outcome from the fitted model.

The fitted one predictor linear model:

$$
\hat{y} = \hat{\beta_0} + \hat{\beta_1} x_1
$$
where $\hat{\beta}$ are the fitted estimates of the true parameters $\beta$ that could be computed if we had the entire population data.

- How did we find $\hat{\beta_0}$ and $\hat{\beta_1}$?

We used the function `linear_reg` with the `lm` engine to fit the model. From the documentation, the 'lm' engine "uses **ordinary least squares** to fit models with numeric outcomes."


## Ordinary Least Squares

The objective of ordinary least squares regression is to find the $\hat{\beta}$ that minimize the sum of square residuals,

$$
\sum_{i=1}^n \epsilon_i ^2
$$
where $n$ is the number of observations (rows in the data) and 

$$
\epsilon_i = y_i - \hat{y_i}
$$

## Exercise 1

[Click here to play with the interactive example](https://seeing-theory.brown.edu/regression-analysis/index.html#section1)

Describe what you see.



## $R^2$ 

Once we fit a model according to the least squares criteria above, how do we assess how well our predictors explain the outcome? We can use a statistic called $R^2$


### Conceptualize $R^2$

Math definition:

$$
R^2 = 1 - \frac{\sum_i^n \epsilon_i^2}{\sum_i^n (y_i - \bar{y})^2}
$$

Word definition:

$$
R^2 = 1 - \frac{\text{sum of squared error}}{\text{sum of square distance from mean in data}}
$$

Let's focus on the second term to build intuition.

- The numerator "sum of squared error" is a measure of how wrong our model is (the  amount of variability *not* explained by the model)

- The denominator is proportional to the variance i.e. the amount of variability in the data.

- Together, the fraction represents the proportion of variability *not* explained by the model.

If the sum of squared error is 0, then the model explains all variability and $R^2 = 1 - 0 = 1$.

If the proportion of error not explained is $1$, i.e. the sum of squared error is the same as all the variability in the data, then model does not explain any variability and $R^2 = 1 - 1 = 0$.

Final take-away: $R^2$ of 0 is a poor fit and $R^2$ of 1 is a perfect fit.

## Example: $R^2$

The single predictor model from last time: bill length explains body mass.

```{r r2-1}
bm_bill_fit = linear_reg() %>%
set_engine("lm") %>%
fit(body_mass_g ~ bill_length_mm, data = penguins)

glance(bm_bill_fit) %>%
  select(r.squared)
```


## Exercise 2

Next, build a multiple regression model with two predictors of body mass: bill length and flipper length. 

- Before writing any code, do you think $R^2$ will increase, decrease or stay the same? Why?


```{r r2-2}
# code here
```


## Exercise 3 

- Now compare 'adjusted' $R^2$ between models. Which model offers the best fit? Why? See [here](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d04-model-multiple-predictors/u4-d04-model-multiple-predictors.html#21) for details on finding adjusted $R^2$.

```{r ex-adj-r-squared}
# code here 
```

## Hypothesis testing in a regression framework

### Exercise 5

Returning to previous joint model,

$$
\text{petal length} = \beta_0 + \beta_{\text{sepal width}} \cdot \text{sepal width} + \beta_{\text{sepal length}} \cdot \text{sepal length}
$$

Does our data offer sufficient evidence that `Sepal.Width` is actualy associated with (and therefore might help us predict) `Petal.Length`?

```{r plot-iris-2}
iris %>%
  ggplot(aes(x = Sepal.Width, y = Petal.Length)) + 
  geom_point() +
  theme_minimal()
```

Let's conduct a hypothesis test in a regression framework to find out.

If `Sepal.Width` does not help explain `Petal.Length`, $\beta_{\text{sepal width}} = 0$, this is our null hypothesis.

- What is the alternative?

For OLS regression, our test statistic is 

$$
T = \frac{\hat{\beta} - 0}{\text{SE}_{\hat{\beta}}} \sim t_{n - 2}
$$
We want to see if our observed statistic, $\hat{T}$, falls far in the tail under the null.

`R` takes care of much of this behind the scenes with the tidy output and reports a p-value for each $\beta$ by default.

Fit the regression model and display the tidy output below.

```{r tidy-regression}
# code here
```

Is $\beta_{\text{sepal width}}$ significant?

## Interactions

```{r}
penguins %>%
  ggplot(aes(x = bill_length_mm, y = body_mass_g, color = island)) +
  geom_point() + 
  theme_bw()
```


### Exercise 6

```{r plot-iris-1}
iris %>%
  ggplot(aes(x = Sepal.Length, y = Petal.Length, color = Species)) + 
  geom_point() +
  scale_color_viridis_d()
```

In the plot above, it appears the relationship between sepal length and petal length, i.e. the slope of `Petal.Length ~ Sepal.Length` varies drastically from one species of iris to another.

- Fit a model with predictors `Sepal.Length`, `Species` and an interaction effect between `Sepal.Length` and `Species`. See [here](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d05-more-model-multiple-predictors/u4-d05-more-model-multiple-predictors.html#23) for example from the prep.

```{r interaction-effect}
# code here
```

- Write the fitted linear model below (using $x$, $y$ notation) but replacing $\beta$s with their fitted values.

[write here]
